{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation of most impotant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing library\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.utils import *\n",
    "from keras.initializers import *\n",
    "import tensorflow as tf\n",
    "import time, random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "batch_size = 64\n",
    "latent_dim = 256\n",
    "num_samples = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization of input data to feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the vectorization process,the collection of text documents is converted into feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 259\n",
      "Number of unique input tokens: 40\n",
      "Number of unique output tokens: 67\n",
      "Max sequence length for inputs: 36\n",
      "Max sequence length for outputs: 47\n"
     ]
    }
   ],
   "source": [
    "#Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_chars = set()\n",
    "target_chars = set()\n",
    "\n",
    "with open('eng_yala.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_chars:\n",
    "            input_chars.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_chars:\n",
    "            target_chars.add(char)\n",
    "\n",
    "input_chars = sorted(list(input_chars))\n",
    "target_chars = sorted(list(target_chars))\n",
    "num_encoder_tokens = len(input_chars)\n",
    "num_decoder_tokens = len(target_chars)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "#Print size\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defining Encoder and Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Define the input data encoder and decoder and the target data for the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define data for encoder and decoder\n",
    "input_token_id = dict([(char, i) for i, char in enumerate(input_chars)])\n",
    "target_token_id = dict([(char, i) for i, char in enumerate(target_chars)])\n",
    "\n",
    "encoder_in_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "\n",
    "decoder_in_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "\n",
    "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_in_data[i, t, input_token_id[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_in_data[i, t, target_token_id[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_id[char]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below lines of codes will define the input sequence for the encoder defined above and process this sequence. After that, an initial state will be set up for the decoder using ‘encoder_states’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define and process the input sequence\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "#We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "#Using `encoder_states` set up the decoder as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below line of code will define the final model that will turn `encoder_in_data` & `decoder_in_data` into `decoder_target_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the final model, we will check it by its summary, data shape and a visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 40)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 67)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 304128      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  331776      input_2[0][0]                    \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 67)     17219       lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 653,123\n",
      "Trainable params: 653,123\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_in_data shape: (259, 36, 40)\n",
      "decoder_in_data shape: (259, 47, 67)\n",
      "decoder_target_data shape: (259, 47, 67)\n"
     ]
    }
   ],
   "source": [
    "#Model data Shape\n",
    "print(\"encoder_in_data shape:\",encoder_in_data.shape)\n",
    "print(\"decoder_in_data shape:\",decoder_in_data.shape)\n",
    "print(\"decoder_target_data shape:\",decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "#Visuaize the model\n",
    "tf.keras.utils.plot_model(model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 5s 626ms/step - loss: 1.0964 - val_loss: 0.9530\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 0.9954 - val_loss: 0.9486\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 1s 168ms/step - loss: 0.9901 - val_loss: 0.9132\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 1s 164ms/step - loss: 0.9243 - val_loss: 0.9094\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 1s 155ms/step - loss: 0.9346 - val_loss: 0.8937\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 1s 161ms/step - loss: 0.8801 - val_loss: 0.8961\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 1s 159ms/step - loss: 0.9277 - val_loss: 0.8965\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 1s 157ms/step - loss: 0.8972 - val_loss: 0.8893\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.9153 - val_loss: 0.8847\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 1s 162ms/step - loss: 0.9110 - val_loss: 0.8865\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 1s 168ms/step - loss: 0.9033 - val_loss: 0.8929\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 1s 156ms/step - loss: 0.8773 - val_loss: 0.8881\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 1s 155ms/step - loss: 0.9021 - val_loss: 0.8849\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 0.8795 - val_loss: 0.8866\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.8907 - val_loss: 0.8846\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 0.8804 - val_loss: 0.8816\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.8936 - val_loss: 0.8841\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 0.8908 - val_loss: 0.8866\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 0.9006 - val_loss: 0.8807\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.9114 - val_loss: 0.8762\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.8908 - val_loss: 0.8821\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 1s 155ms/step - loss: 0.8780 - val_loss: 0.8755\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 0.8907 - val_loss: 0.8747\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.9117 - val_loss: 0.8740\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 1s 157ms/step - loss: 0.8850 - val_loss: 0.8677\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.8494 - val_loss: 0.8752\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.8552 - val_loss: 0.8672\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.8593 - val_loss: 0.8651\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.8314 - val_loss: 0.8683\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.8492 - val_loss: 0.8655\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.8578 - val_loss: 0.8673\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.8277 - val_loss: 0.8662\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.8453 - val_loss: 0.8626\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.8337 - val_loss: 0.8690\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 0.8525 - val_loss: 0.8619\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.8208 - val_loss: 0.8704\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.8506 - val_loss: 0.8634\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 1s 161ms/step - loss: 0.8381 - val_loss: 0.8622\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.8027 - val_loss: 0.8595\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 1s 167ms/step - loss: 0.8384 - val_loss: 0.8564\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.8225 - val_loss: 0.8610\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.8044 - val_loss: 0.8592\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 0.8304 - val_loss: 0.8600\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 1s 161ms/step - loss: 0.8045 - val_loss: 0.8528\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 1s 157ms/step - loss: 0.8054 - val_loss: 0.8538\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.8003 - val_loss: 0.8531\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 1s 158ms/step - loss: 0.7907 - val_loss: 0.8564\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.7962 - val_loss: 0.8556\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.7739 - val_loss: 0.8598\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.8075 - val_loss: 0.8574\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 0.7902 - val_loss: 0.8573\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.8216 - val_loss: 0.8492\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 1s 157ms/step - loss: 0.7888 - val_loss: 0.8738\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.8159 - val_loss: 0.8494\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.7679 - val_loss: 0.8509\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 0.8056 - val_loss: 0.8580\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.7969 - val_loss: 0.8630\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.7803 - val_loss: 0.8472\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.7747 - val_loss: 0.8614\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.7962 - val_loss: 0.8531\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.7868 - val_loss: 0.8415\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.7557 - val_loss: 0.8506\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 1s 155ms/step - loss: 0.7827 - val_loss: 0.8518\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 0.8064 - val_loss: 0.8511\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 1s 167ms/step - loss: 0.7668 - val_loss: 0.8560\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.7517 - val_loss: 0.8524\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.7647 - val_loss: 0.8542\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.7906 - val_loss: 0.8504\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 0.7482 - val_loss: 0.8543\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 1s 157ms/step - loss: 0.7906 - val_loss: 0.8572\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.7727 - val_loss: 0.8472\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.7752 - val_loss: 0.8524\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.7692 - val_loss: 0.8490\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.7524 - val_loss: 0.8426\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 1s 162ms/step - loss: 0.7882 - val_loss: 0.8548\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 1s 155ms/step - loss: 0.7658 - val_loss: 0.8478\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 1s 155ms/step - loss: 0.7678 - val_loss: 0.8446\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.7589 - val_loss: 0.8434\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.7291 - val_loss: 0.8530\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 1s 155ms/step - loss: 0.7387 - val_loss: 0.8386\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.7463 - val_loss: 0.8483\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.7543 - val_loss: 0.8433\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 150ms/step - loss: 0.7509 - val_loss: 0.8479\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 0.7438 - val_loss: 0.8512\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.7552 - val_loss: 0.8510\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.7587 - val_loss: 0.8544\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 0.7319 - val_loss: 0.8514\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 1s 161ms/step - loss: 0.7412 - val_loss: 0.8483\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 0.7507 - val_loss: 0.8483\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 1s 163ms/step - loss: 0.7551 - val_loss: 0.8475\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 0.7411 - val_loss: 0.8536\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.7566 - val_loss: 0.8480\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.7259 - val_loss: 0.8438\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.7196 - val_loss: 0.8465\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 0.7505 - val_loss: 0.8442\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 0.7344 - val_loss: 0.8485\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.7409 - val_loss: 0.8451\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 1s 156ms/step - loss: 0.7344 - val_loss: 0.8474\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 1s 159ms/step - loss: 0.7414 - val_loss: 0.8451\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 1s 157ms/step - loss: 0.7026 - val_loss: 0.8473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22c533d3a90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compiling and training the model\n",
    "epochs =100\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.001), loss='categorical_crossentropy')\n",
    "\n",
    "model.fit([encoder_in_data, decoder_in_data], decoder_target_data, batch_size = batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the sample model using the parameters of the trained model to test language translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lstm_model.h5')\n",
    "encoder_model.save('encoder_model.h5')\n",
    "decoder_model.save('decoder_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below part of codes will define the decode sequence for the text that we will pass to the model as the input sequence. This\n",
    "could be understood as the module for translating the input language into the target language. In this part, the input sequence\n",
    "is encoded into the state vectors. The state vector and the target sequence is passed to the decoder and it produces the \n",
    "prediction for the next character. Using these predictions, the next character is sampled and it is appended to the target\n",
    "sequence. This process is repeated to generate until the end of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, char) for char, i in input_token_id.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_id.items())\n",
    "\n",
    "#Define Decode Sequence\n",
    "def decode_sequence(input_seq):\n",
    "    #Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    #Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    #Get the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_id['\\t']] = 1.\n",
    "\n",
    "    #Sampling loop for a batch of sequences\n",
    "    #(to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        #Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        #Exit condition: either hit max length\n",
    "        #or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        #Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        #Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will check our model to decode the input sequence into the target sequence, i.e., translate the English sentences\n",
    "into the French sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: a        lot!\n",
      "Decoded sentence: obi̍                                            \n",
      "-\n",
      "Input sentence: A week later!\n",
      "Decoded sentence: obi̍                                            \n",
      "-\n",
      "Input sentence: also!        \n",
      "Decoded sentence: obi̍                                            \n",
      "-\n",
      "Input sentence: always       \n",
      "Decoded sentence: obi̍                                            \n",
      "-\n",
      "Input sentence: ancestors   \n",
      "Decoded sentence: obi̍                                            \n",
      "-\n",
      "Input sentence: and         \n",
      "Decoded sentence: obi̍                                            \n",
      "-\n",
      "Input sentence: and you     \n",
      "Decoded sentence: obi̍                                            \n",
      "-\n",
      "Input sentence: angels      \n",
      "Decoded sentence: obi̍                                            \n",
      "-\n",
      "Input sentence: another     \n",
      "Decoded sentence: obi̍                                            \n",
      "-\n",
      "Input sentence: another place\n",
      "Decoded sentence: obi̍                                            \n",
      "-\n",
      "Input sentence: another time \n",
      "Decoded sentence: obi̍                                            \n",
      "-\n",
      "Input sentence: answer       \n",
      "Decoded sentence: obi̍                                            \n",
      "-\n",
      "Input sentence: answer her   \n",
      "Decoded sentence: obi̍                                            \n",
      "-\n",
      "Input sentence: Anywhere at all \n",
      "Decoded sentence: obi̍                                            \n",
      "-\n",
      "Input sentence: we are still going to\n",
      "Decoded sentence: obi̍                                            \n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(15):\n",
    "    input_seq = encoder_in_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Ilya Sutskever et al, ‘Sequence to Sequence Learning with Neural Networks’, arXiv.org.\n",
    "\n",
    "2.K Cho et al, ‘Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation’, arXiv.org.\n",
    "\n",
    "3.Keras tutorial on ‘Sequence to sequence example in Keras (character-level)’.\n",
    "\n",
    "4.Keras tutorial on ‘A ten-minute introduction to sequence-to-sequence learning in Keras’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
